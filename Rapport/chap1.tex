\section{Méthodes itératives et motivation}
    Les méthodes itératives apparaissent comme une alternative aux méthodes de solution directe , où la vrai solution n'est pas recherchée et une bonne approximation suffit.

    L'idée consiste à trouver, après un nombre définit d'itérations, une suite ${x_{k}}$ qui converge à $x$, la solution exacte du problème \ref{eq:suite}.

    \begin{equation}\label{eq:suite}
        x = lim_{k \to \infty} x_{k}
    \end{equation}

    La méthode est appliquée de façon à s'arrêter après $k$ itérations, où $x_{k}$ est le premier élément de la suite à satisfaire la condition \ref{eq:ch1_it}.

    \begin{equation}\label{eq:ch1_it}
       \frac{||x_{k} - x||}{||x||} \leq \epsilon
    \end{equation}

    Où $\epsilon$ est une tolérance définie par qui l'applique.

    Normalement $x$ n'est pas connue, de façon que \ref{eq:ch1_it} est changée pour \ref{eq:residual}, où $A$ est la matrice du système linéaire et $b$ le RHS(Right Hand Side).

    \begin{equation}\label{eq:residual}
        \frac{||Ax_{k} - b||}{||b||} \leq \epsilon
    \end{equation}

    Les premiers méthodes itératives utilisaient une décomposition de la matrice $A$ comme une combinaison de deux matrices \ref{eq:A-comb}, où $A_{1}$ est inversible, et chaque itération serait définie comme \ref{eq:A_it}.

    \begin{equation}\label{eq:A-comb}
        A = A_{1} - A_{2}
    \end{equation}

    \begin{equation}\label{eq:A_it}
        A_{1} x_{k+1} = b + A_{2}x_{k}
    \end{equation}

    Avec une substitution des autres $x_{k}$, \ref{eq:A_it} donne \ref{eq:it_fin}, qui converge n'importe quelle solution initiale ssi $\rho(A_{2}A_{1}^{-1}) < 1$, où $\rho(X)$ est le rayon spectral de la matrice X \cite{bonnet}.

    \begin{equation}\label{eq:it_fin}
        x_{k+1} = A_{1}^{-1}(b + A_{2}x_{k}) = A_{1}^{-1}(b + A_{2}A_{1}^{-1}(b + A_{2}x_{k-1}))... = A_{1}^{-1} \left[ \sum_{i=0}^{k} (A_{2}A_{1}^{-1})^{i}b\right]
    \end{equation}

    Si $A_{1} = I$ et $A_{2} = I - A$ en \ref{eq:A-comb}, la suite trouvée en \ref{eq:it_fin} est: $x_{1} = b$,$x_{2} = 2b- Ab$, $x_{3} = 3b-3Ab+A^{2}b$ , ...

    Même que la condition $\rho(A-I) \leq 1$ soit restrictive \cite{bonnet}, cela nous montre qu'une approximation $x_{k}$ peut être représentée comme \ref{eq:xkry}.

    \begin{equation}\label{eq:xkry}
        x_{k} \in span(b,Ab,A^{2}b,...,A^{k-1}b)
    \end{equation}

    \section{Sous-espace de Krylov}
    Soit $A \in \mathbb{K}^{n \times n}$ une matrice et $b\in \mathbb{K}^{n}$. Pour $k\leq n$ le sous-espace de Krylov $\mathcal{K}_{k}=\mathcal{K}_{k}(A,b)$ associé à A,b est défini comme \ref{eq:krylov}.

    \begin{equation}\label{eq:krylov}
        \mathcal{K}_{k}(A,b) = span(b,Ab,A^{2}b,\dots , A^{k-1}b)
    \end{equation}

    Ces sous-espaces suivent aussi la propriété: $k<l \to \mathcal{K}^{k} \subset \mathcal{K}^{l}$ \cite{bonnet}.

    Ce sous-espace $\mathcal{K}_{k}(A,b)$ est aussi le sous-espace de tous les vecteurs de $\mathbb{R}^{m}$ qui peuvent être écrits comme $x=p(A)b$, où $p(A)$ est un polynôme de degré inférieur à $k-1$ dont $p(0)=1$.

    Le problème avec l'utilisation de ${A^{k}b}, k \in {0,1,2,\dots}$ comme une base vient du fait que les produits successifs de la matrice $A$ font des vecteurs qui sont \textit{presque colinéaires}, vu que ceux sont proches du vecteur propre du plus grand valeur propre de la matrice $A$.

    \section{Méthode d'Arnoldi}
    
    Dans le but d'obtenir une base orthonormale pour $\mathcal{K}_{k}(A,b)$, le méthode cherche une matrice unitaire $Q$ tel que l'expression \ref{eq:init_arnoldi} est valide. $H_{k}={h_{ij}}$ est une matrice de Hessenberg.

    \begin{equation} \label{eq:init_arnoldi}
        AQ_{k} = Q_{k+1}H_{k}
    \end{equation} 

    Pour chaque vecteur-colonne de $Q$, $q_{i}$, \ref{eq:init_arnoldi} peut être écrite comme \ref{eq:final_arnoldi}, où la représentation de $\mathcal{K}_{k}(A,b)$ avec une base orthonormal devient plus claire. Dans une application pratique, $Q$ est initialisée avec $q_{1} = \frac{b}{||b||}$.

    \begin{equation}\label{eq:final_arnoldi}
        Aq_{m} = h_{1m}q_{1} + h_{2m}q_{2} + \dots h_{m+1,m}q_{m+1}
    \end{equation}

    Un algorithme pour la méthode peut être trouvée en \ref{alg:arnoldi}.

     \begin{algorithm}
    \caption{Itération k dArnoldi}\label{alg:arnoldi}
    \begin{algorithmic}[1]
    \State $A \in \mathbb{K}^{n \times n}$ et $b\in \mathbb{K}^{n}$
    \State $x=0, \beta=\norm{b},q_{1}=\frac{b}{\beta}$
    
    \For{$j=1,2,\dots k$}
    \State $q_{j+1} = Aq_{j}$

    \For{ $i=1,2,\dots j$}
    \State $h_{ij}= q_{j+1}^{t}q_{i}$
    \State $q_{j+1} = q_{j+1} - h_{ij}q_{i}$
    \EndFor
    \State $h_{j+1,j}=\norm{q_{j+1}}$
    \State $q_{j+1} = \frac{q_{j+1}}{h_{j+1,j}}$
    \EndFor
    
    \end{algorithmic}
    \end{algorithm}